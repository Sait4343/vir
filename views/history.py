import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
import pytz
import math

# üî• –Ü–º–ø–æ—Ä—Ç –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î (–∑–∞–º—ñ—Å—Ç—å globals)
from utils.db import supabase

def show_history_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ —ñ—Å—Ç–æ—Ä—ñ—ó —Å–∫–∞–Ω—É–≤–∞–Ω—å.
    –í–ï–†–°–Ü–Ø: MODULAR + PROFILES MAPPING.
    1. –ë–µ—Ä–µ user_email –∑ scan_results.
    2. –®—É–∫–∞—î –≤–ª–∞—Å–Ω–∏–∫–∞ –≤ —Ç–∞–±–ª–∏—Ü—ñ 'profiles'.
    3. –§–æ—Ä–º—É—î –ü–Ü–ë (first_name + last_name).
    """

    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å—É
    KYIV_TZ = pytz.timezone('Europe/Kiev')

    # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —Å–∫–∏–¥–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
    def reset_page():
        st.session_state.history_page_number = 1

    if 'history_page_number' not in st.session_state:
        st.session_state.history_page_number = 1

    # --- –ü–ï–†–ï–í–Ü–†–ö–ê –ü–†–û–ï–ö–¢–£ ---
    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    st.title("üìú –Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å")

    # --- 2. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• ---
    with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó..."):
        try:
            # 1. Keywords
            kw_resp = supabase.table("keywords").select("id, keyword_text").eq("project_id", proj["id"]).execute()
            kw_map = {k['id']: k['keyword_text'] for k in kw_resp.data} if kw_resp.data else {}

            # 2. Scans (–ë–µ—Ä–µ–º–æ user_email)
            scans_resp = supabase.table("scan_results")\
                .select("id, created_at, provider, keyword_id, user_email")\
                .eq("project_id", proj["id"])\
                .order("created_at", desc=True)\
                .limit(1000)\
                .execute()
            
            scans_data = scans_resp.data if scans_resp.data else []
            
            if not scans_data:
                st.info("–Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å –ø–æ—Ä–æ–∂–Ω—è.")
                return

            scan_ids = [s['id'] for s in scans_data]

            # üî• 3. –û–¢–†–ò–ú–ê–ù–ù–Ø –ü–Ü–ë –ó –¢–ê–ë–õ–ò–¶–Ü PROFILES
            unique_emails = list(set([s['user_email'] for s in scans_data if s.get('user_email')]))
            email_to_name_map = {}

            if unique_emails:
                try:
                    # ‚ö†Ô∏è –ó–º—ñ–Ω–µ–Ω–æ —Ç–∞–±–ª–∏—Ü—é –Ω–∞ 'profiles'
                    p_resp = supabase.table("profiles")\
                        .select("email, first_name, last_name")\
                        .in_("email", unique_emails)\
                        .execute()
                    
                    if p_resp.data:
                        for p in p_resp.data:
                            f_n = p.get('first_name', '') or ''
                            l_n = p.get('last_name', '') or ''
                            full_n = f"{f_n} {l_n}".strip()
                            
                            # –Ø–∫—â–æ —ñ–º'—è –∑–Ω–∞–π–¥–µ–Ω–µ, –∑–∞–ø–∏—Å—É—î–º–æ –π–æ–≥–æ –≤ –º–∞–ø—É
                            if full_n and p.get('email'):
                                email_to_name_map[p['email']] = full_n
                except Exception:
                    # –Ø–∫—â–æ —Ç–∞–±–ª–∏—Ü—ñ profiles –Ω–µ–º–∞—î –∞–±–æ –ø–æ–º–∏–ª–∫–∞ –¥–æ—Å—Ç—É–ø—É
                    pass

            # 4. Mentions
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —á–∞–Ω–∫–∏, —è–∫—â–æ ID –¥—É–∂–µ –±–∞–≥–∞—Ç–æ
            chunk_size = 200
            all_mentions = []
            all_sources = []
            
            for i in range(0, len(scan_ids), chunk_size):
                chunk = scan_ids[i:i + chunk_size]
                m_resp = supabase.table("brand_mentions").select("scan_result_id, is_my_brand, mention_count").in_("scan_result_id", chunk).execute()
                if m_resp.data: all_mentions.extend(m_resp.data)
                
                s_resp = supabase.table("extracted_sources").select("scan_result_id, is_official").in_("scan_result_id", chunk).execute()
                if s_resp.data: all_sources.extend(s_resp.data)

            mentions_df = pd.DataFrame(all_mentions)
            sources_df = pd.DataFrame(all_sources)

        except Exception as e:
            if "column scan_results.user_email does not exist" in str(e):
                st.error("‚ö†Ô∏è –í—ñ–¥—Å—É—Ç–Ω—è –∫–æ–ª–æ–Ω–∫–∞ `user_email` —É —Ç–∞–±–ª–∏—Ü—ñ scan_results.")
            else:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
            return

    # --- 3. –û–ë–†–û–ë–ö–ê –î–ê–ù–ò–• ---
    df_scans = pd.DataFrame(scans_data)

    # üî• –õ–û–ì–Ü–ö–ê –Ü–ù–Ü–¶–Ü–ê–¢–û–†–ê
    def resolve_initiator(email_val):
        # 1. –Ø–∫—â–æ –µ–º–µ–π–ª –ø—É—Å—Ç–∏–π -> –ê–≤—Ç–æ
        if pd.isna(email_val) or str(email_val).strip() == "" or str(email_val).lower() == "none":
            return "ü§ñ –ê–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è"
        
        # 2. –Ø–∫—â–æ –º–∏ –∑–Ω–∞–π—à–ª–∏ —ñ–º'—è —É profiles -> –í–∏–≤–æ–¥–∏–º–æ –ü–Ü–ë
        if email_val in email_to_name_map:
            return f"üë§ {email_to_name_map[email_val]}"
        
        # 3. –Ø–∫—â–æ —ñ–º–µ–Ω—ñ –Ω–µ –∑–Ω–∞–π—à–ª–∏ (–ø—Ä–æ—Ñ—ñ–ª—å –Ω–µ –∑–∞–ø–æ–≤–Ω–µ–Ω–∏–π) -> –í–∏–≤–æ–¥–∏–º–æ Email
        return f"üë§ {email_val}"
    
    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ, —è–∫—â–æ –∫–æ–ª–æ–Ω–∫–∞ —î
    if 'user_email' in df_scans.columns:
        df_scans['initiator'] = df_scans['user_email'].apply(resolve_initiator)
    else:
        df_scans['initiator'] = "ü§ñ –ê–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è"

    # –ü—Ä–æ–≤–∞–π–¥–µ—Ä–∏
    PROVIDER_MAP = {"gpt-4o": "OpenAI", "gpt-4-turbo": "OpenAI", "gemini-1.5-pro": "Gemini", "perplexity": "Perplexity"}
    df_scans['provider'] = df_scans['provider'].replace(PROVIDER_MAP)
    
    # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
    df_scans['keyword'] = df_scans['keyword_id'].map(kw_map).fillna("–í–∏–¥–∞–ª–µ–Ω–∏–π –∑–∞–ø–∏—Ç")
    
    # Timezone Fix
    df_scans['created_at_dt'] = pd.to_datetime(df_scans['created_at'])
    if df_scans['created_at_dt'].dt.tz is None:
        df_scans['created_at_dt'] = df_scans['created_at_dt'].dt.tz_localize('UTC')
    df_scans['created_at_dt'] = df_scans['created_at_dt'].dt.tz_convert(KYIV_TZ)
    
    # Merge (–ë–µ–∑–ø–µ—á–Ω–µ –∑–ª–∏—Ç—Ç—è)
    if not mentions_df.empty:
        brands_count = mentions_df.groupby('scan_result_id').size().reset_index(name='total_brands')
        my_mentions = mentions_df[mentions_df['is_my_brand'] == True].groupby('scan_result_id')['mention_count'].sum().reset_index(name='my_mentions_count')
        
        df_scans = df_scans.merge(brands_count, left_on='id', right_on='scan_result_id', how='left')
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
        
        df_scans = df_scans.merge(my_mentions, left_on='id', right_on='scan_result_id', how='left')
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
    else:
        df_scans['total_brands'] = 0
        df_scans['my_mentions_count'] = 0

    if not sources_df.empty:
        links_count = sources_df.groupby('scan_result_id').size().reset_index(name='total_links')
        off_count = sources_df[sources_df['is_official'] == True].groupby('scan_result_id').size().reset_index(name='official_links')
        
        df_scans = df_scans.merge(links_count, left_on='id', right_on='scan_result_id', how='left')
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
        
        df_scans = df_scans.merge(off_count, left_on='id', right_on='scan_result_id', how='left')
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
    else:
        df_scans['total_links'] = 0
        df_scans['official_links'] = 0

    df_scans = df_scans.fillna(0)

    # --- 4. –§–Ü–õ–¨–¢–†–ò ---
    st.markdown("### üîç –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è")
    
    now_kyiv = datetime.now(KYIV_TZ).date()
    
    if not df_scans.empty:
        min_date_avail = df_scans['created_at_dt'].min().date()
        max_date_avail = max(df_scans['created_at_dt'].max().date(), now_kyiv) + timedelta(days=1)
    else:
        min_date_avail = now_kyiv
        max_date_avail = now_kyiv + timedelta(days=1)

    c1, c2, c3, c4 = st.columns([1, 1.2, 1, 0.8])
    
    with c1:
        all_providers = df_scans['provider'].unique().tolist()
        sel_providers = st.multiselect("–ú–æ–¥–µ–ª—å", all_providers, default=all_providers, on_change=reset_page)
    
    with c2:
        default_start = now_kyiv - timedelta(days=30)
        sel_dates = st.date_input(
            "–ü–µ—Ä—ñ–æ–¥",
            value=(default_start, now_kyiv),
            min_value=min_date_avail - timedelta(days=365),
            max_value=max_date_avail
        )
        
    with c3:
        sort_opts = ["–ù–∞–π–Ω–æ–≤—ñ—à—ñ", "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ", "–ë—ñ–ª—å—à–µ –∑–≥–∞–¥–æ–∫", "–û—Ñ—ñ—Ü. –¥–∂–µ—Ä–µ–ª–∞"]
        sel_sort = st.selectbox("–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è", sort_opts, on_change=reset_page)

    with c4:
        rows_per_page = st.selectbox("–†—è–¥–∫—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä.", [10, 20, 50, 100, 200], index=0, on_change=reset_page)

    # --- –ó–ê–°–¢–û–°–£–í–ê–ù–ù–Ø –§–Ü–õ–¨–¢–†–Ü–í ---
    mask = df_scans['provider'].isin(sel_providers)
    
    if isinstance(sel_dates, tuple):
        if len(sel_dates) == 2:
            start_d, end_d = sel_dates
            mask &= (df_scans['created_at_dt'].dt.date >= start_d)
            mask &= (df_scans['created_at_dt'].dt.date <= end_d)
        elif len(sel_dates) == 1:
            mask &= (df_scans['created_at_dt'].dt.date == sel_dates[0])
        
    df_filtered = df_scans[mask].copy()

    # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
    if sel_sort == "–ù–∞–π–Ω–æ–≤—ñ—à—ñ": df_filtered = df_filtered.sort_values('created_at_dt', ascending=False)
    elif sel_sort == "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ": df_filtered = df_filtered.sort_values('created_at_dt', ascending=True)
    elif sel_sort == "–ë—ñ–ª—å—à–µ –∑–≥–∞–¥–æ–∫": df_filtered = df_filtered.sort_values('my_mentions_count', ascending=False)
    elif sel_sort == "–û—Ñ—ñ—Ü. –¥–∂–µ—Ä–µ–ª–∞": df_filtered = df_filtered.sort_values('official_links', ascending=False)

    # --- 5. –ü–ê–ì–Ü–ù–ê–¶–Ü–Ø ---
    total_rows = len(df_filtered)
    total_pages = math.ceil(total_rows / rows_per_page)
    
    if st.session_state.history_page_number > total_pages:
        st.session_state.history_page_number = max(1, total_pages)
    
    current_page = st.session_state.history_page_number
    start_idx = (current_page - 1) * rows_per_page
    end_idx = start_idx + rows_per_page
    
    df_display_page = df_filtered.iloc[start_idx:end_idx].copy()

    # --- 6. –í–Ü–î–û–ë–†–ê–ñ–ï–ù–ù–Ø (AUTO HEIGHT) ---
    st.divider()
    
    p_col1, p_col2, p_col3 = st.columns([1, 2, 1])
    with p_col1:
        if current_page > 1:
            if st.button("‚¨ÖÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—è", key="hist_prev_top"):
                st.session_state.history_page_number -= 1
                st.rerun()
    with p_col2:
        st.markdown(f"<div style='text-align: center; padding-top: 5px;'>–°—Ç–æ—Ä—ñ–Ω–∫–∞ <b>{current_page}</b> –∑ <b>{total_pages}</b> (–í—Å—å–æ–≥–æ: {total_rows})</div>", unsafe_allow_html=True)
    with p_col3:
        if current_page < total_pages:
            if st.button("–ù–∞—Å—Ç—É–ø–Ω–∞ ‚û°Ô∏è", key="hist_next_top"):
                st.session_state.history_page_number += 1
                st.rerun()

    if 'created_at_dt' in df_display_page.columns:
        df_display_page['created_at_dt'] = df_display_page['created_at_dt'].dt.strftime('%d.%m.%Y %H:%M')

    cols_to_show = ['created_at_dt', 'keyword', 'provider', 'total_brands', 'total_links', 'my_mentions_count', 'official_links', 'initiator']
    df_show = df_display_page[[c for c in cols_to_show if c in df_display_page.columns]]

    # –ê–≤—Ç–æ-–≤–∏—Å–æ—Ç–∞
    dynamic_height = (len(df_show) * 35) + 38

    st.dataframe(
        df_show,
        use_container_width=True,
        hide_index=True,
        height=dynamic_height,
        column_config={
            "created_at_dt": "–î–∞—Ç–∞ (Kyiv)",
            "keyword": st.column_config.TextColumn("–ó–∞–ø–∏—Ç", width="medium"),
            "provider": "LLM",
            "total_brands": st.column_config.NumberColumn("–ë—Ä–µ–Ω–¥–∏", help="–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤"),
            "total_links": st.column_config.NumberColumn("–ü–æ—Å–∏–ª.", help="–í—Å—å–æ–≥–æ –¥–∂–µ—Ä–µ–ª"),
            "my_mentions_count": st.column_config.NumberColumn("–ó–≥–∞–¥–∫–∏", help="–ó–≥–∞–¥–∫–∏ –Ω–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É"),
            "official_links": st.column_config.NumberColumn("–û—Ñ—ñ—Ü.", help="–û—Ñ—ñ—Ü—ñ–π–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞"),
            "initiator": st.column_config.TextColumn("–Ü–Ω—ñ—Ü—ñ–∞—Ç–æ—Ä", help="–•—Ç–æ –∑–∞–ø—É—Å—Ç–∏–≤", width="medium")
        }
    )

    if total_rows > 10:
        st.write("")
        b_col1, b_col2, b_col3 = st.columns([1, 2, 1])
        with b_col1:
            if current_page > 1:
                if st.button("‚¨ÖÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—è", key="hist_prev_btm"):
                    st.session_state.history_page_number -= 1
                    st.rerun()
        with b_col3:
            if current_page < total_pages:
                if st.button("–ù–∞—Å—Ç—É–ø–Ω–∞ ‚û°Ô∏è", key="hist_next_btm"):
                    st.session_state.history_page_number += 1
                    st.rerun()
